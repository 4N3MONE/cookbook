{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9uMH4XjQQCh"
      },
      "source": [
        "## Code Search with Vector Embeddings and Qdrant\n",
        "\n",
        "*Authored by: [Qdrant Team](https://github.com/qdrant/qdrant)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2J2A8i2QQCi"
      },
      "source": [
        " In this notebook, we demonstrate how you can use vector embeddings to navigate a codebase, to help you find relevant code snippets. We'll search codebases using natural semantic queries, and search for code based on a similar logic.\n",
        "\n",
        "You can check out the [live deployment](https://code-search.qdrant.tech/) of this approach which exposes the Qdrant codebase for search with a web interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPXQ2PAzQQCi"
      },
      "source": [
        "### The approach\n",
        "\n",
        "- General usage neural encoder for Natural Language Processing (NLP), in our case `all-MiniLM-L6-v2` from the sentence-transformers library. We'll call this NLP model.\n",
        "- Specialized embeddings for code-to-code similarity search. We use the `jina-embeddings-v2-base-code` model. We'll call this code model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTKLHLfXQQCj"
      },
      "source": [
        "To prepare our code for `all-MiniLM-L6-v2`, we preprocess the code to text that more closely resembles natural language. The Jina embeddings model supports a variety of standard programming languages, so there is no need to preprocess the snippets. We can use the code as is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkYeQHOMQQCj"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "Chunking the application sources into smaller parts is a non-trivial task. In general, functions, class methods, structs, enums, and all the other language-specific constructs are good candidates for chunks. They are big enough to contain some meaningful information, but small enough to be processed by embedding models with a limited context window. You can also use docstrings, comments, and other metadata can be used to enrich the chunks with additional information.\n",
        "\n",
        "<div style=\"text-align:center\"><img src=\"https://huggingface.co/datasets/Anush008/cookbook-images/resolve/main/data-chunking.png\" /></div>\n",
        "\n",
        "NLP-based search is based on function signatures, but code search may return smaller pieces, such as loops. So, if we receive a particular function signature from the NLP model and part of its implementation from the code model, we merge the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiwwXvDSQQCj"
      },
      "source": [
        "### Parsing the Codebaase\n",
        "\n",
        "We'll use the [Qdrant codebase](https://github.com/qdrant/qdrant) for this demo.\n",
        "While this codebase uses Rust, you can use this approach with any other language. You can use an [Language Server Protocol (LSP)](https://microsoft.github.io/language-server-protocol/) tool to build a graph of the codebase, and then extract chunks. We did our work with the [rust-analyzer](https://rust-analyzer.github.io/). We exported the parsed codebase into the [LSIF](https://microsoft.github.io/language-server-protocol/specifications/lsif/0.4.0/specification/) format, a standard for code intelligence data. Next, we used the LSIF data to navigate the codebase and extract the chunks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMjHzBg-QQCj"
      },
      "source": [
        "> For other languages, you can use the same approach. There are [plenty of implementations](https://microsoft.github.io/language-server-protocol/implementors/servers/) available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-F3D3xPQQCj"
      },
      "source": [
        "We then exported the chunks into JSON documents with not only the code itself, but also context with the location of the code in the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJwhq8qbQQCj"
      },
      "source": [
        "You can examine the Qdrant structures, parsed in JSON, in the [structures.jsonl file](https://storage.googleapis.com/tutorial-attachments/code-search/structures.jsonl) in our Google Cloud Storage bucket. Download it and use it as a source of data for our code search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc-kqwqLQQCj"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/tutorial-attachments/code-search/structures.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io57rPHNQQCk"
      },
      "source": [
        "Next, load the file and parse the lines into a list of dictionaries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0Z0vjTfQQCk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "structures = []\n",
        "with open(\"structures.jsonl\", \"r\") as fp:\n",
        "    for i, row in enumerate(fp):\n",
        "        entry = json.loads(row)\n",
        "        structures.append(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A6pI3ElQQCk"
      },
      "source": [
        "Let's see how one entry looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZEBXstzQQCk",
        "outputId": "2fa6e247-c722-428a-c266-3031ea2af0e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'InvertedIndexRam',\n",
              " 'signature': '# [doc = \" Inverted flatten index from dimension id to posting list\"] # [derive (Debug , Clone , PartialEq)] pub struct InvertedIndexRam { # [doc = \" Posting lists for each dimension flattened (dimension id -> posting list)\"] # [doc = \" Gaps are filled with empty posting lists\"] pub postings : Vec < PostingList > , # [doc = \" Number of unique indexed vectors\"] # [doc = \" pre-computed on build and upsert to avoid having to traverse the posting lists.\"] pub vector_count : usize , }',\n",
              " 'code_type': 'Struct',\n",
              " 'docstring': '= \" Inverted flatten index from dimension id to posting list\"',\n",
              " 'line': 15,\n",
              " 'line_from': 13,\n",
              " 'line_to': 22,\n",
              " 'context': {'module': 'inverted_index',\n",
              "  'file_path': 'lib/sparse/src/index/inverted_index/inverted_index_ram.rs',\n",
              "  'file_name': 'inverted_index_ram.rs',\n",
              "  'struct_name': None,\n",
              "  'snippet': '/// Inverted flatten index from dimension id to posting list\\n#[derive(Debug, Clone, PartialEq)]\\npub struct InvertedIndexRam {\\n    /// Posting lists for each dimension flattened (dimension id -> posting list)\\n    /// Gaps are filled with empty posting lists\\n    pub postings: Vec<PostingList>,\\n    /// Number of unique indexed vectors\\n    /// pre-computed on build and upsert to avoid having to traverse the posting lists.\\n    pub vector_count: usize,\\n}\\n'}}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "structures[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaKCggNgQQCk"
      },
      "source": [
        "### Code to natural language conversion\n",
        "\n",
        "Each programming language has its own syntax which is not a part of the natural language. Thus, a general-purpose model probably does not understand the code as is. We can, however, normalize the data by removing code specifics and including additional context, such as module, class, function, and file name. We took the following steps:\n",
        "\n",
        "1. Extract the signature of the function, method, or other code construct.\n",
        "2. Divide camel case and snake case names into separate words.\n",
        "3. Take the docstring, comments, and other important metadata.\n",
        "4. Build a sentence from the extracted data using a predefined template.\n",
        "5. Remove the special characters and replace them with spaces.\n",
        "6. As input, expect dictionaries with the same structure. Define a `textify` function to do the conversion. We’ll use an `inflection` library to convert with different naming conventions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZYinELLQQCk"
      },
      "outputs": [],
      "source": [
        "%pip install inflection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbmUDCb9QQCk"
      },
      "source": [
        "We can now define the textify function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubGOBozmQQCk"
      },
      "outputs": [],
      "source": [
        "import inflection\n",
        "import re\n",
        "\n",
        "from typing import Dict, Any\n",
        "\n",
        "def textify(chunk: Dict[str, Any]) -> str:\n",
        "    # Get rid of all the camel case / snake case\n",
        "    # - inflection.underscore changes the camel case to snake case\n",
        "    # - inflection.humanize converts the snake case to human readable form\n",
        "    name = inflection.humanize(inflection.underscore(chunk[\"name\"]))\n",
        "    signature = inflection.humanize(inflection.underscore(chunk[\"signature\"]))\n",
        "\n",
        "    # Check if docstring is provided\n",
        "    docstring = \"\"\n",
        "    if chunk[\"docstring\"]:\n",
        "        docstring = f\"that does {chunk['docstring']} \"\n",
        "\n",
        "    # Extract the location of that snippet of code\n",
        "    context = (\n",
        "        f\"module {chunk['context']['module']} \"\n",
        "        f\"file {chunk['context']['file_name']}\"\n",
        "    )\n",
        "    if chunk[\"context\"][\"struct_name\"]:\n",
        "        struct_name = inflection.humanize(\n",
        "            inflection.underscore(chunk[\"context\"][\"struct_name\"])\n",
        "        )\n",
        "        context = f\"defined in struct {struct_name} {context}\"\n",
        "\n",
        "    # Combine all the bits and pieces together\n",
        "    text_representation = (\n",
        "        f\"{chunk['code_type']} {name} \"\n",
        "        f\"{docstring}\"\n",
        "        f\"defined as {signature} \"\n",
        "        f\"{context}\"\n",
        "    )\n",
        "\n",
        "    # Remove any special characters and concatenate the tokens\n",
        "    tokens = re.split(r\"\\W\", text_representation)\n",
        "    tokens = filter(lambda x: x, tokens)\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hlqx9MGQQCk"
      },
      "source": [
        "Now we can use `textify` to convert all chunks into text representations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6VEQnuIQQCk"
      },
      "outputs": [],
      "source": [
        "text_representations = list(map(textify, structures))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_GlAXvXQQCl"
      },
      "source": [
        "Let's see how one of our representations looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zosN7TC9QQCl",
        "outputId": "7909b5dd-4e32-4ee3-e669-97fe0eec5e84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Function Hnsw discover precision that does Checks discovery search precision when using hnsw index this is different from the tests in defined as Fn hnsw discover precision module integration file hnsw_discover_test rs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "text_representations[1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QXn9c57QQCl"
      },
      "source": [
        "Let's begin generating embeddings for our data. We'll use [FastEmbed](https://github.com/qdrant/fastembed) - A CPU-first, lightweight library for generating vector embeddings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install https://github.com/qdrant/fastembed/archive/jina-embeddings-v2-base-code.zip"
      ],
      "metadata": {
        "id": "Wb0ZlmE3SWxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM4h4wQcQQCl"
      },
      "source": [
        "### Natural language embeddings\n",
        "\n",
        "We can encode text representations through the [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "95b4c831935e46368366ac9a50523ca3",
            "8270cdacd2bf4a67b4bfed7742f56489",
            "be9060ff40844157bd85a17228acbcd1",
            "3103ccfb4eea4096b7ec38aaa45f4fcc",
            "dc7562c9505e4f729d763c8c56726979",
            "d760eac53f5b4c9f8f1640398e6004fe",
            "2a1e1fe6e6454c48bc6e7ef5ed15f7b9",
            "44c23a2d4df344369f8638b4767038e9",
            "ae7c5ec238b8413b83699debc126617e",
            "79f81996c5a34e0b8161161368d22082",
            "2b29f883064642489a62bfa2afc37715"
          ]
        },
        "id": "7gp7y_jYQQCl",
        "outputId": "1e8fe7d6-e56d-42b8-ef43-a7d5cb15a235"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95b4c831935e46368366ac9a50523ca3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from fastembed import TextEmbedding\n",
        "\n",
        "nlp_model = TextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "nlp_embeddings = list(nlp_model.embed(text_representations, parallel=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQZft9BqQQCl"
      },
      "source": [
        "### Code Embeddings\n",
        "\n",
        "We'll be using [jinaai/jina-embeddings-v2-base-code](https://huggingface.co/jinaai/jina-embeddings-v2-base-code) for the task. It supports English and 30 widely used programming languages with a 8192 sequence length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPqV4sDJQQCl"
      },
      "outputs": [],
      "source": [
        "code_snippets = [\n",
        "    structure[\"context\"][\"snippet\"] for structure in structures\n",
        "]\n",
        "\n",
        "code_model = TextEmbedding(\"jinaai/jina-embeddings-v2-base-code\")\n",
        "\n",
        "code_embeddings = list(code_model.embed(code_snippets, parallel=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm4KSxVeQQCl"
      },
      "source": [
        "### Building Qdrant collection\n",
        "\n",
        "We use the `qdrant-client` library to interact with the Qdrant server. Let’s install that client:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPKrzkK3QQCl"
      },
      "outputs": [],
      "source": [
        "%pip install qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcU_BileQQCl"
      },
      "source": [
        "Qdrant supports multiple modes of deployment. Including in-memory for prototyping, Docker and Qdrant Cloud. You can refer to the [installation instructions](https://qdrant.tech/documentation/guides/installation/) for more information.\n",
        "\n",
        "We'll continue the tutorial using an in-memory instance.\n",
        "\n",
        "> NOTE: In-memory can only be used for quick-prototyping and tests. It is a Python based implementation of the Qdrant server methods.\n",
        "\n",
        "Let's create a collection to store our vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOLKqa7sQQCl"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")  # Use in-memory storage\n",
        "# client = QdrantClient(location=\"localhost:6333\")  # For Qdrant server\n",
        "\n",
        "client.create_collection(\n",
        "    \"qdrant-sources\",\n",
        "    vectors_config={\n",
        "        \"text\": models.VectorParams(\n",
        "            size=nlp_embeddings[0].shape[0],\n",
        "            distance=models.Distance.COSINE,\n",
        "        ),\n",
        "        \"code\": models.VectorParams(\n",
        "            size=code_embeddings[0].shape[0],\n",
        "            distance=models.Distance.COSINE,\n",
        "        ),\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixffRmB0QQCl"
      },
      "source": [
        "Our newly created collection is ready to accept the data. Let’s upload the embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jBAVfB7QQCm"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "points = [\n",
        "    models.PointStruct(\n",
        "        id=uuid.uuid4().hex,\n",
        "        vector={\n",
        "            \"text\": text_embedding,\n",
        "            \"code\": code_embedding,\n",
        "        },\n",
        "        payload=structure,\n",
        "    )\n",
        "    for text_embedding, code_embedding, structure in zip(nlp_embeddings, code_embeddings, structures)\n",
        "]\n",
        "\n",
        "client.upload_points(\"qdrant-sources\", points=points, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCRXvkJZQQCm"
      },
      "source": [
        "The uploaded points are immediately available for search. Next, query the collection to find relevant code snippets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGV-Qc2MQQCm"
      },
      "source": [
        "### Querying the codebase\n",
        "\n",
        "We use one of the models to search the collection via Qdrant's new [Query API](https://qdrant.tech/blog/qdrant-1.10.x/). Start with text embeddings. Run the following query “How do I count points in a collection?”. Review the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUoLe_SyQQCm"
      },
      "outputs": [],
      "source": [
        "query = \"How do I count points in a collection?\"\n",
        "\n",
        "hits = client.query_points(\n",
        "    \"qdrant-sources\",\n",
        "    query=next(nlp_model.query_embed(query)).tolist(),\n",
        "    using=\"text\",\n",
        "    limit=5,\n",
        ").points\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2vbMhW2QQCm"
      },
      "source": [
        "Now, review the results. The following table lists the module, the file name\n",
        "and score. Each line includes a link to the signature, as a code block from\n",
        "the file.\n",
        "\n",
        "| module             | file_name           | score      | signature                                                                                                                                                                                                                                                                                 |\n",
        "|--------------------|---------------------|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| toc                | point_ops.rs        | 0.59448624 | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub async fn count`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/storage/src/content_manager/toc/point_ops.rs#L120)                          |\n",
        "| operations         | types.rs            | 0.5493385  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub struct CountRequestInternal`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/collection/src/operations/types.rs#L831)                       |\n",
        "| collection_manager | segments_updater.rs | 0.5121002  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub(crate) fn upsert_points<'a, T>`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/collection/src/collection_manager/segments_updater.rs#L339) |\n",
        "| collection         | point_ops.rs        | 0.5063539  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub async fn count`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/collection/src/collection/point_ops.rs#L213)                                |\n",
        "| map_index          | mod.rs              | 0.49973983 | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn get_points_with_value_count<Q>`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/segment/src/index/field_index/map_index/mod.rs#L88)          |\n",
        "\n",
        "It seems we were able to find some relevant code structures. Let's try the same with the code embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2vczTXCQQCm"
      },
      "outputs": [],
      "source": [
        "hits = client.query_points(\n",
        "    \"qdrant-sources\",\n",
        "    query=next(code_model.query_embed(query)).tolist(),\n",
        "    using=\"code\",\n",
        "    limit=5,\n",
        ").points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24gl0XfIQQCp"
      },
      "source": [
        "Output:\n",
        "\n",
        "| module        | file_name                  | score      | signature                                                                                                                                                                                                                                                                   |\n",
        "|---------------|----------------------------|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| field_index   | geo_index.rs               | 0.73278356 | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/segment/src/index/field_index/geo_index.rs#L612)         |\n",
        "| numeric_index | mod.rs                     | 0.7254976  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/numeric_index/mod.rs#L322) |\n",
        "| map_index     | mod.rs                     | 0.7124739  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/map_index/mod.rs#L315)     |\n",
        "| map_index     | mod.rs                     | 0.7124739  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/map_index/mod.rs#L429)     |\n",
        "| fixtures      | payload_context_fixture.rs | 0.706204   | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn total_point_count`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/fixtures/payload_context_fixture.rs#L122)       |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo4HFN1SQQCp"
      },
      "source": [
        "While the scores retrieved by different models are not comparable, but we can\n",
        "see that the results are different. Code and text embeddings can capture\n",
        "different aspects of the codebase. We can use both models to query the collection\n",
        "and then combine the results to get the most relevant code snippets, from a single batch request."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import models\n",
        "\n",
        "hits = client.query_points(\n",
        "    collection_name=\"qdrant-sources\",\n",
        "    prefetch=[\n",
        "        models.Prefetch(\n",
        "            query=next(nlp_model.query_embed(query)).tolist(),\n",
        "            using=\"text\",\n",
        "            limit=5,\n",
        "        ),\n",
        "        models.Prefetch(\n",
        "            query=next(code_model.query_embed(query)).tolist(),\n",
        "            using=\"code\",\n",
        "            limit=5,\n",
        "        ),\n",
        "    ],\n",
        ").points"
      ],
      "metadata": {
        "id": "266Erpi2VdLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzFwrz1LQQCp"
      },
      "source": [
        "Output:\n",
        "\n",
        "| module             | file_name                  | score      | signature                                                                                                                                                                                                                                                                                 |\n",
        "|--------------------|----------------------------|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| toc                | point_ops.rs               | 0.59448624 | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub async fn count`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/storage/src/content_manager/toc/point_ops.rs#L120)                          |\n",
        "| operations         | types.rs                   | 0.5493385  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub struct CountRequestInternal`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/collection/src/operations/types.rs#L831)                       |\n",
        "| collection_manager | segments_updater.rs        | 0.5121002  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub(crate) fn upsert_points<'a, T>`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/collection/src/collection_manager/segments_updater.rs#L339) |\n",
        "| collection         | point_ops.rs               | 0.5063539  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `pub async fn count`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/collection/src/collection/point_ops.rs#L213)                                |\n",
        "| map_index          | mod.rs                     | 0.49973983 | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn get_points_with_value_count<Q>`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/segment/src/index/field_index/map_index/mod.rs#L88)          |\n",
        "| field_index        | geo_index.rs               | 0.73278356 | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/segment/src/index/field_index/geo_index.rs#L612)                       |\n",
        "| numeric_index      | mod.rs                     | 0.7254976  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/numeric_index/mod.rs#L322)               |\n",
        "| map_index          | mod.rs                     | 0.7124739  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/map_index/mod.rs#L315)                   |\n",
        "| map_index          | mod.rs                     | 0.7124739  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/map_index/mod.rs#L429)                   |\n",
        "| fixtures           | payload_context_fixture.rs | 0.706204   | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn total_point_count`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/fixtures/payload_context_fixture.rs#L122)                     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjG6JKy7QQCp"
      },
      "source": [
        "This is one example of how you can use different models and combine the results.\n",
        "In a real-world scenario, you might run some reranking and deduplication, as\n",
        "well as additional processing of the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFiW5eO3QQCp"
      },
      "source": [
        "### Grouping the results\n",
        "\n",
        "You can improve the search results, by grouping them by payload properties.\n",
        "In our case, we can group the results by the module. If we use code embeddings,\n",
        "we can see multiple results from the `map_index` module. Let's group the\n",
        "results and assume a single result per module:\n",
        "\n",
        "> NOTE: The query API doesn't support grouping yet. We'll use the older search API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVBkf-zrQQCp"
      },
      "outputs": [],
      "source": [
        "results = client.search_groups(\n",
        "    \"qdrant-sources\",\n",
        "    query_vector=(\n",
        "        \"code\", next(code_model.query_embed(query)).tolist(),\n",
        "    ),\n",
        "    group_by=\"context.module\",\n",
        "    limit=5,\n",
        "    group_size=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmmOVXMXQQCp"
      },
      "source": [
        "| module        | file_name                  | score      | signature                                                                                                                                                                                                                                                                   |\n",
        "|---------------|----------------------------|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| field_index   | geo_index.rs               | 0.73278356 | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/7aa164bd2dda1c0fc9bf3a0da42e656c95c2e52a/lib/segment/src/index/field_index/geo_index.rs#L612)         |\n",
        "| numeric_index | mod.rs                     | 0.7254976  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/numeric_index/mod.rs#L322) |\n",
        "| map_index     | mod.rs                     | 0.7124739  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn count_indexed_points`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/field_index/map_index/mod.rs#L315)     |\n",
        "| fixtures      | payload_context_fixture.rs | 0.706204   | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn total_point_count`](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/fixtures/payload_context_fixture.rs#L122)       |\n",
        "| hnsw_index    | graph_links.rs             | 0.6998417  | [<img src=\"/documentation/tutorials/code-search/github-mark.png\" width=\"16\" style=\"display: inline\"> `fn num_points `](https://github.com/qdrant/qdrant/blob/3fbe1cae6cb7f51a0c5bb4b45cfe6749ac76ed59/lib/segment/src/index/hnsw_index/graph_links.rs#L477)                 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxiuYai_QQCq"
      },
      "source": [
        "That concludes our tutorial. Thanks for taking the time to get here."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95b4c831935e46368366ac9a50523ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8270cdacd2bf4a67b4bfed7742f56489",
              "IPY_MODEL_be9060ff40844157bd85a17228acbcd1",
              "IPY_MODEL_3103ccfb4eea4096b7ec38aaa45f4fcc"
            ],
            "layout": "IPY_MODEL_dc7562c9505e4f729d763c8c56726979"
          }
        },
        "8270cdacd2bf4a67b4bfed7742f56489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d760eac53f5b4c9f8f1640398e6004fe",
            "placeholder": "​",
            "style": "IPY_MODEL_2a1e1fe6e6454c48bc6e7ef5ed15f7b9",
            "value": "Fetching 5 files: 100%"
          }
        },
        "be9060ff40844157bd85a17228acbcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c23a2d4df344369f8638b4767038e9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae7c5ec238b8413b83699debc126617e",
            "value": 5
          }
        },
        "3103ccfb4eea4096b7ec38aaa45f4fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f81996c5a34e0b8161161368d22082",
            "placeholder": "​",
            "style": "IPY_MODEL_2b29f883064642489a62bfa2afc37715",
            "value": " 5/5 [00:00&lt;00:00, 161.95it/s]"
          }
        },
        "dc7562c9505e4f729d763c8c56726979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d760eac53f5b4c9f8f1640398e6004fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1e1fe6e6454c48bc6e7ef5ed15f7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44c23a2d4df344369f8638b4767038e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7c5ec238b8413b83699debc126617e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79f81996c5a34e0b8161161368d22082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b29f883064642489a62bfa2afc37715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}