{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A RAG Ebook \"Librarian\" Using LlamaIndex\n",
    "\n",
    "_Authored by: [Jonathan Jin](https://huggingface.co/jinnovation)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to quickly build a RAG-based \"librarian\" for your\n",
    "local ebook library.\n",
    "\n",
    "Think about the last time you visited a library and took advantage of the\n",
    "expertise of the knowledgeable staff there to help you find what you need out of\n",
    "the troves of textbooks, novels, and other resources at the library. Our RAG\n",
    "\"librarian\" will do the same for us, except for our own local collection of\n",
    "ebooks.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "We'd like our librarian to be **lightweight** and **run locally as much as\n",
    "possible** with **minimal dependencies**. This means that we will leverage\n",
    "open-source to the fullest extent possible, as well as bias towards models that\n",
    "can be **executed locally on typical hardware, e.g. M1 Macbooks**.\n",
    "\n",
    "## Components\n",
    "\n",
    "Our solution will consist of the following components:\n",
    "\n",
    "- [LlamaIndex], a data framework for LLM-based applications that's, unlike\n",
    "  [LangChain], designed specifically for RAG;\n",
    "- [Ollama], a user-friendly solution for running LLMs such as Llama 2 locally;\n",
    "- The [`BAAI/bge-base-en-v1.5`](https://huggingface.co/BAAI/bge-base-en-v1.5)\n",
    "  embedding model, which performs [reasonably well and is reasonably lightweight\n",
    "  in size](https://huggingface.co/spaces/mteb/leaderboard);\n",
    "- [Llama 2], which we'll run via [Ollama].\n",
    "\n",
    "[LlamaIndex]: https://docs.llamaindex.ai/en/stable/index.html\n",
    "[LangChain]: https://python.langchain.com/docs/get_started/introduction\n",
    "[Ollama]: https://ollama.com/\n",
    "[Llama 2]: https://ollama.com/library/llama2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "First let's install our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \\\n",
    "    llama-index \\\n",
    "    EbookLib \\\n",
    "    html2text \\\n",
    "    llama-index-embeddings-huggingface \\\n",
    "    llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Library Setup\n",
    "\n",
    "Next, let's create our test \"library.\"\n",
    "\n",
    "For simplicity's sake, let's say that our \"library\" is simply a **nested directory of `.epub` files**. We can easily see this solution generalizing to, say, a Calibre library with a `metadata.db` database file. We'll leave that extension as an exercise for the reader. 😇\n",
    "\n",
    "Let's pull two `.epub` files from [Project Gutenberg](https://www.gutenberg.org/) for our library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \".test/library/jane-austen\"\n",
    "!mkdir -p \".test/library/victor-hugo\"\n",
    "!wget https://www.gutenberg.org/ebooks/1342.epub.noimages -O \".test/library/jane-austen/pride-and-prejudice.epub\"\n",
    "!wget https://www.gutenberg.org/ebooks/135.epub.noimages -O \".test/library/victor-hugo/les-miserables.epub\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with LlamaIndex\n",
    "\n",
    "RAG with LlamaIndex, at its core, consists of the following broad phases:\n",
    "\n",
    "1. **Loading**, in which you tell LlamaIndex where your data lives and how to\n",
    "   load it;\n",
    "2. **Indexing**, in which you augment your loaded data to facilitate querying, e.g. with vector embeddings;\n",
    "3. **Querying**, in which you configure an LLM to act as the query interface for\n",
    "   your indexed data.\n",
    "\n",
    "This explanation only scratches at the surface of what's possible with\n",
    "LlamaIndex. For more in-depth details, I highly recommend reading the\n",
    "[\"High-Level Concepts\" page of the LlamaIndex\n",
    "documentation](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading\n",
    "\n",
    "Naturally, let's start with the **loading** phase.\n",
    "\n",
    "I mentioned before that LlamaIndex is designed specifically for RAG. This\n",
    "immediately becomes obvious from its\n",
    "[`SimpleDirectoryReader`](https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader.html)\n",
    "construct, which ✨ **magically** ✨ supports a whole host of multi-model file\n",
    "types for free. Conveniently for us, `.epub` is in the supported set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjin/dev/calibre-lookup/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "    input_dir=\"./.test/\",\n",
    "    recursive=True,\n",
    "    required_exts=[\".epub\"],\n",
    ")\n",
    "\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimpleDirectoryReader.load_data()` converts our ebooks into a set of [`Document`s](https://docs.llamaindex.ai/en/stable/api/llama_index.core.schema.Document.html) for LlamaIndex to work with.\n",
    "\n",
    "One important thing to note here is that the documents **have not been chunked at this stage** -- that will happen during indexing. Read on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Next up after **loading** the data is to **index** it. This will allow our RAG pipeline to look up the relevant context for our query to pass to our LLM to **augment** their generated response. This is also where document chunking will take place.\n",
    "\n",
    "[`VectorStoreIndex`](https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index.html)\n",
    "is a \"default\" entrypoint for indexing in LlamaIndex. By default,\n",
    "`VectorStoreIndex` uses a simple, in-memory dictionary to store the indices, but\n",
    "LlamaIndex also supports [a wide variety of vector storage\n",
    "solutions](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores.html)\n",
    "for you to graduate to as you scale.\n",
    "\n",
    "<Tip> \n",
    "By default, LlamaIndex uses a chunk size of 1024 and a chunk overlap of\n",
    "20. For more details, see the [LlamaIndex\n",
    "documentation](https://docs.llamaindex.ai/en/stable/optimizing/basic_strategies/basic_strategies.html#chunk-sizes).\n",
    "</Tip>\n",
    "\n",
    "\n",
    "Like mentioned before, we'll use the\n",
    "[`BAAI/bge-small-en-v1.5`](https://huggingface.co/BAAI/bge-base-en-v1.5) to\n",
    "generate our embeddings. By default, [LlamaIndex uses\n",
    "OpenAI](https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html)\n",
    "(specifically `gpt-3.5-turbo`), which we'd like to avoid given our desire for a lightweight, locally-runnable end-to-end solution.\n",
    "\n",
    "Thankfully, LlamaIndex supports retrieving embedding models from Hugging Face through the convenient `HuggingFaceEmbedding` class, so we'll use that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pass that in to `VectorStoreIndex` as our embedding model to circumvent the OpenAI default behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying\n",
    "\n",
    "Now for the final piece of the RAG puzzle -- wiring up the query layer.\n",
    "\n",
    "We'll use Llama 2 for the purposes of this recipe, but I encourage readers to play around with different models to see which produces the \"best\" responses here.\n",
    "\n",
    "First let's start up the Ollama server. Unfortunately, there is no support in the [Ollama Python client](https://github.com/ollama/ollama-python) for actually starting and stopping the server itself, so we'll have to pop out of Python land for this.\n",
    "\n",
    "In a separate terminal, run: `ollama serve`. Remember to terminate this after we're done here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's hook Llama 2 up to LlamaIndex and use it as the basis of our query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llama = Ollama(\n",
    "    model=\"llama2\",\n",
    "    request_timeout=40.0,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result\n",
    "\n",
    "With that, our basic RAG librarian is set up and we can start asking questions about our library. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, there are two books available:\n",
      "\n",
      "1. \"Pride and Prejudice\" by Jane Austen\n",
      "2. \"Les Misérables\" by Victor Hugo\n",
      "\n",
      "The context used to derive this answer includes:\n",
      "\n",
      "* The file path for each book, which provides information about the location of the book files on the computer.\n",
      "* The titles of the books, which are mentioned in the context as being available for reading.\n",
      "* A list of words associated with each book, such as \"epub\" and \"notebooks\", which provide additional information about the format and storage location of each book.\n"
     ]
    }
   ],
   "source": [
    "print(query_engine.query(\"What are the titles of all the books available? Show me the context used to derive your answer.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main character of 'Pride and Prejudice' is Elizabeth Bennet.\n"
     ]
    }
   ],
   "source": [
    "print(query_engine.query(\"Who is the main character of 'Pride and Prejudice'?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Improvements\n",
    "\n",
    "We've demonstrated how to build a basic RAG-based \"librarian\" that runs entirely locally, even on Apple silicon Macs. In doing so, we've also carried out a \"grand tour\" of LlamaIndex and how it streamlines the process of setting up RAG-based applications.\n",
    "\n",
    "That said, we've really only scratched the surface of what's possible here. Here are some ideas of how to refine and build upon this foundation.\n",
    "\n",
    "### Forcing Citations\n",
    "\n",
    "To guard against the risk of our librarian hallucinating, how might we require that it provide citations for everything that it says?\n",
    "\n",
    "### Using Extended Metadata\n",
    "\n",
    "Ebook library management solutions like [Calibre](https://calibre-ebook.com/) create additional metadata for ebooks in a library. This can provide information such as publisher or edition that might not be readily available in the text of the book itself. How could we extend our RAG pipeline to account for additional sources of information that aren't `.epub` files?\n",
    "\n",
    "### Efficient Indexing\n",
    "\n",
    "If we were to collect everything we built here into a script/executable, the resulting script would re-index our library on each invocation. For our tiny test library of two files, this is \"fine,\" but for any library of non-trivial size this will very quickly become annoying for users. How could we persist the embedding indices and only update them when the contents of the library have meaningfully changed, e.g. new books have been added?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "## Quote Counting\n",
    "\n",
    "Our librarian, unfortunately, hallucinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line of dialogue \"The party seemed so well selected, so suitable one with the other. I hope we may often meet again\" is said in Chapter LIII of 'Pride and Prejudice'.\n"
     ]
    }
   ],
   "source": [
    "resp = query_engine.query(\n",
    "    \"In which chapter of 'Pride and Prejudice' is the following line of dialogue said: 'The party seemed so well selected, so suitable one with the other. I hope we may often meet again.'\"\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is incorrect; this line is spoken in [Chapter 54](https://fiatlux-day.org/e2a/literature/pride-prejudice/pride-prejudice-16.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First order of business is to get the query engine to not hallucinate.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to debug exactly how the query engine arrived at this response.\n",
    "\n",
    "First let's take a look at the **source nodes** that were sent to the LLM for response synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I am very glad you liked\\n'\n",
      " 'her. I hope she will turn out well.”\\n'\n",
      " '\\n'\n",
      " '“I dare say she will; she has got over the most trying age.”\\n'\n",
      " '\\n'\n",
      " '“Did you go by the village of Kympton?”\\n'\n",
      " '\\n'\n",
      " '“I do not recollect that we did.”\\n'\n",
      " '\\n'\n",
      " '“I mention it because it is the living which I ought to have had. A most\\n'\n",
      " 'delightful place! Excellent parsonage-house! It would have suited me in '\n",
      " 'every\\n'\n",
      " 'respect.”\\n'\n",
      " '\\n'\n",
      " '“How should you have liked making sermons?”\\n'\n",
      " '\\n'\n",
      " '“Exceedingly well. I should have considered it as part of my duty, and the\\n'\n",
      " 'exertion would soon have been nothing. One ought not to repine; but, to be\\n'\n",
      " 'sure, it would have been such a thing for me! The quiet, the retirement of\\n'\n",
      " 'such a life, would have answered all my ideas of happiness! But it was not '\n",
      " 'to\\n'\n",
      " 'be. Did you ever hear Darcy mention the circumstance when you were in '\n",
      " 'Kent?”\\n'\n",
      " '\\n'\n",
      " '“I _have_ heard from authority, which I thought _as good_ , that it was '\n",
      " 'left\\n'\n",
      " 'you conditionally only, and at the will of the present patron.”\\n'\n",
      " '\\n'\n",
      " '“You have! Yes, there was something in _that_ ; I told you so from the '\n",
      " 'first,\\n'\n",
      " 'you may remember.”\\n'\n",
      " '\\n'\n",
      " '“I _did_ hear, too, that there was a time when sermon-making was not so\\n'\n",
      " 'palatable to you as it seems to be at present; that you actually declared '\n",
      " 'your\\n'\n",
      " 'resolution of never taking orders, and that the business had been '\n",
      " 'compromised\\n'\n",
      " 'accordingly.”\\n'\n",
      " '\\n'\n",
      " '“You did! and it was not wholly without foundation. You may remember what I\\n'\n",
      " 'told you on that point, when first we talked of it.”\\n'\n",
      " '\\n'\n",
      " 'They were now almost at the door of the house, for she had walked fast to '\n",
      " 'get\\n'\n",
      " 'rid of him; and unwilling, for her sister’s sake, to provoke him, she only\\n'\n",
      " 'said in reply, with a good-humoured smile,—\\n'\n",
      " '\\n'\n",
      " '“Come, Mr. Wickham, we are brother and sister, you know. Do not let us '\n",
      " 'quarrel\\n'\n",
      " 'about the past. In future, I hope we shall be always of one mind.”\\n'\n",
      " '\\n'\n",
      " 'She held out her hand: he kissed it with affectionate gallantry, though he\\n'\n",
      " 'hardly knew how to look, and they entered the house.\\n'\n",
      " '\\n'\n",
      " '##  [Image unavailable.]  \\n'\n",
      " '“Mr. Darcy with him.”  \\n'\n",
      " '  \\n'\n",
      " 'CHAPTER LIII.\\n'\n",
      " '\\n'\n",
      " 'MR. WICKHAM was so perfectly satisfied with this conversation, that he '\n",
      " 'never\\n'\n",
      " 'again distressed himself, or provoked his dear sister Elizabeth, by\\n'\n",
      " 'introducing the subject of it; and she was pleased to find that she had '\n",
      " 'said\\n'\n",
      " 'enough to keep him quiet.\\n'\n",
      " '\\n'\n",
      " 'The day of his and Lydia’s departure soon came; and Mrs. Bennet was forced '\n",
      " 'to\\n'\n",
      " 'submit to a separation, which, as her husband by no means entered into her\\n'\n",
      " 'scheme of their all going to Newcastle, was likely to continue at least a\\n'\n",
      " 'twelvemonth.\\n'\n",
      " '\\n'\n",
      " '“Oh, my dear Lydia,” she cried, “when shall we meet again?”\\n'\n",
      " '\\n'\n",
      " '“Oh, Lord! I don’t know. Not these two or three years, perhaps.”\\n'\n",
      " '\\n'\n",
      " '“Write to me very often, my dear.”\\n'\n",
      " '\\n'\n",
      " '“As often as I can. But you know married women have never much time for\\n'\n",
      " 'writing. My sisters may write to _me_. They will have nothing else to do.”\\n'\n",
      " '\\n'\n",
      " 'Mr. Wickham’s adieus were much more affectionate than his wife’s. He '\n",
      " 'smiled,\\n'\n",
      " 'looked handsome, and said many pretty things.\\n'\n",
      " '\\n'\n",
      " '“He is as fine a fellow,” said Mr. Bennet, as soon as they were out of the\\n'\n",
      " 'house, “as ever I saw. He simpers, and smirks, and makes love to us all. I '\n",
      " 'am\\n'\n",
      " 'prodigiously proud of him. I defy even Sir William Lucas himself to produce '\n",
      " 'a\\n'\n",
      " 'more valuable son-in-law.”\\n'\n",
      " '\\n'\n",
      " 'The loss of her daughter made Mrs. Bennet very dull for several days.\\n'\n",
      " '\\n'\n",
      " '“I often think,” said she, “that there is nothing so bad as parting with '\n",
      " 'one’s\\n'\n",
      " 'friends. One seems so forlorn without them.”\\n'\n",
      " '\\n'\n",
      " '“This is the consequence, you see, madam, of marrying a daughter,” said\\n'\n",
      " 'Elizabeth. “It must make you better satisfied that your other four are\\n'\n",
      " 'single.”\\n'\n",
      " '\\n'\n",
      " '“It is no such thing. Lydia does not leave me because she is married; but '\n",
      " 'only\\n'\n",
      " 'because her husband’s regiment happens to be so far off.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(resp.source_nodes[0].node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('“He has made me so happy,” said she, one evening, “by telling me that he '\n",
      " 'was\\n'\n",
      " 'totally ignorant of my being in town last spring! I had not believed it\\n'\n",
      " 'possible.”\\n'\n",
      " '\\n'\n",
      " '“I suspected as much,” replied Elizabeth. “But how did he account for it?”\\n'\n",
      " '\\n'\n",
      " '“It must have been his sisters’ doing. They were certainly no friends to '\n",
      " 'his\\n'\n",
      " 'acquaintance with me, which I cannot wonder at, since he might have chosen '\n",
      " 'so\\n'\n",
      " 'much more advantageously in many respects. But when they see, as I trust '\n",
      " 'they\\n'\n",
      " 'will, that their brother is happy with me, they will learn to be contented,\\n'\n",
      " 'and we shall be on good terms again: though we can never be what we once '\n",
      " 'were\\n'\n",
      " 'to each other.”\\n'\n",
      " '\\n'\n",
      " '“That is the most unforgiving speech,” said Elizabeth, “that I ever heard '\n",
      " 'you\\n'\n",
      " 'utter. Good girl! It would vex me, indeed, to see you again the dupe of '\n",
      " 'Miss\\n'\n",
      " 'Bingley’s pretended regard.”\\n'\n",
      " '\\n'\n",
      " '“Would you believe it, Lizzy, that when he went to town last November he\\n'\n",
      " 'really loved me, and nothing but a persuasion of _my_ being indifferent '\n",
      " 'would\\n'\n",
      " 'have prevented his coming down again?”\\n'\n",
      " '\\n'\n",
      " '“He made a little mistake, to be sure; but it is to the credit of his\\n'\n",
      " 'modesty.”\\n'\n",
      " '\\n'\n",
      " 'This naturally introduced a panegyric from Jane on his diffidence, and the\\n'\n",
      " 'little value he put on his own good qualities.\\n'\n",
      " '\\n'\n",
      " 'Elizabeth was pleased to find that he had not betrayed the interference of '\n",
      " 'his\\n'\n",
      " 'friend; for, though Jane had the most generous and forgiving heart in the\\n'\n",
      " 'world, she knew it was a circumstance which must prejudice her against him.\\n'\n",
      " '\\n'\n",
      " '“I am certainly the most fortunate creature that ever existed!” cried Jane.\\n'\n",
      " '“Oh, Lizzy, why am I thus singled from my family, and blessed above them '\n",
      " 'all?\\n'\n",
      " 'If I could but see you as happy! If there were but such another man for '\n",
      " 'you!”\\n'\n",
      " '\\n'\n",
      " '“If you were to give me forty such men I never could be so happy as you. '\n",
      " 'Till\\n'\n",
      " 'I have your disposition, your goodness, I never can have your happiness. '\n",
      " 'No,\\n'\n",
      " 'no, let me shift for myself; and, perhaps, if I have very good luck, I may\\n'\n",
      " 'meet with another Mr. Collins in time.”\\n'\n",
      " '\\n'\n",
      " 'The situation of affairs in the Longbourn family could not be long a '\n",
      " 'secret.\\n'\n",
      " 'Mrs. Bennet was privileged to whisper it to Mrs. Philips, and she ventured,\\n'\n",
      " 'without any permission, to do the same by all her neighbours in Meryton.\\n'\n",
      " '\\n'\n",
      " 'The Bennets were speedily pronounced to be the luckiest family in the '\n",
      " 'world;\\n'\n",
      " 'though only a few weeks before, when Lydia had first run away, they had '\n",
      " 'been\\n'\n",
      " 'generally proved to be marked out for misfortune.\\n'\n",
      " '\\n'\n",
      " '##  \\n'\n",
      " '  \\n'\n",
      " 'CHAPTER LVI.\\n'\n",
      " '\\n'\n",
      " 'ONE morning, about a week after Bingley’s engagement with Jane had been\\n'\n",
      " 'formed, as he and the females of the family were sitting together in the\\n'\n",
      " 'dining-room, their attention was suddenly drawn to the window by the sound '\n",
      " 'of\\n'\n",
      " 'a carriage; and they perceived a chaise and four driving up the lawn. It '\n",
      " 'was\\n'\n",
      " 'too early in the morning for visitors; and besides, the equipage did not\\n'\n",
      " 'answer to that of any of their neighbours. The horses were post; and '\n",
      " 'neither\\n'\n",
      " 'the carriage, nor the livery of the servant who preceded it, were familiar '\n",
      " 'to\\n'\n",
      " 'them. As it was certain, however, that somebody was coming, Bingley '\n",
      " 'instantly\\n'\n",
      " 'prevailed on Miss Bennet to avoid the confinement of such an intrusion, and\\n'\n",
      " 'walk away with him into the shrubbery. They both set off; and the '\n",
      " 'conjectures\\n'\n",
      " 'of the remaining three continued, though with little satisfaction, till the\\n'\n",
      " 'door was thrown open, and their visitor entered. It was Lady Catherine de\\n'\n",
      " 'Bourgh.\\n'\n",
      " '\\n'\n",
      " 'They were of course all intending to be surprised: but their astonishment '\n",
      " 'was\\n'\n",
      " 'beyond their expectation; and on the part of Mrs. Bennet and Kitty, though '\n",
      " 'she\\n'\n",
      " 'was perfectly unknown to them, even inferior to what Elizabeth felt.\\n'\n",
      " '\\n'\n",
      " 'She entered the room with an air more than usually ungracious, made no '\n",
      " 'other\\n'\n",
      " 'reply to Elizabeth’s salutation than a slight inclination of the head, and '\n",
      " 'sat\\n'\n",
      " 'down without saying a word. Elizabeth had mentioned her name to her mother '\n",
      " 'on\\n'\n",
      " 'her Ladyship’s entrance, though no request of introduction had been made.\\n'\n",
      " '\\n'\n",
      " 'Mrs. Bennet, all amazement, though flattered by having a guest of such high\\n'\n",
      " 'importance, received her with the utmost politeness. After sitting for a\\n'\n",
      " 'moment in silence, she said, very stiffly, to Elizabeth,—\\n'\n",
      " '\\n'\n",
      " '“I hope you are well, Miss Bennet.')\n"
     ]
    }
   ],
   "source": [
    "pprint(resp.source_nodes[1].node.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
